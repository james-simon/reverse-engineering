{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fig 1: shallow nets can approximate any kernel",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX0oNTOYzgaR"
      },
      "source": [
        "# Figure 1\n",
        "We show that arbitrary kernels can be accurately achieved by shallow networks with engineered pointwise nonlinearities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH4fGMESBDHk"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5VOmEC2AS_I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ab5cc3-0611-4999-b559-117cdbf49891"
      },
      "source": [
        "!pip install -q git+https://www.github.com/google/neural-tangents\n",
        "!sudo apt-get install texlive-latex-recommended\n",
        "!sudo apt install texlive-latex-extra\n",
        "!sudo apt install dvipng\n",
        "!sudo apt install cm-super dvipng\n",
        "!pip install pmlb\n",
        "!pip install cifar10_web\n",
        "\n",
        "import cifar10_web\n",
        "\n",
        "import cvxopt\n",
        "\n",
        "import jax.nn\n",
        "import jax.numpy as np\n",
        "from jax import random\n",
        "from jax.api import jit, grad, vmap\n",
        "from jax.config import config\n",
        "from jax.experimental import optimizers\n",
        "from jax.ops import index_update\n",
        "\n",
        "import neural_tangents as nt\n",
        "from neural_tangents import stax\n",
        "\n",
        "import numpy as base_np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from scipy.special import factorial, factorial2\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "config.update(\"jax_enable_x64\", True)\n",
        "\n",
        "np.set_printoptions(precision=4, linewidth=200)\n",
        "\n",
        "key = random.PRNGKey(17)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for neural-tangents (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "texlive-latex-recommended is already the newest version (2017.20180305-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "texlive-latex-extra is already the newest version (2017.20180305-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "dvipng is already the newest version (1.15-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cm-super is already the newest version (0.3.4-11).\n",
            "dvipng is already the newest version (1.15-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: pmlb in /usr/local/lib/python3.7/dist-packages (1.0.1.post3)\n",
            "Requirement already satisfied: requests>=2.24.0 in /usr/local/lib/python3.7/dist-packages (from pmlb) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.7/dist-packages (from pmlb) (5.4.1)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from pmlb) (1.1.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pmlb) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pmlb) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pmlb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pmlb) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->pmlb) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->pmlb) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.5->pmlb) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0.5->pmlb) (1.15.0)\n",
            "Requirement already satisfied: cifar10_web in /usr/local/lib/python3.7/dist-packages (0.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DK0qgtHDTPoM"
      },
      "source": [
        "# Datasetup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-11wrm2K0tXP"
      },
      "source": [
        "Of the CIFAR-10 dataset, we get the first 10k training images and 10k testing images. We normalize the data such that the norm is $\\sqrt{n_0}$ where $n_0$ is the input dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YscBjquUCjAi"
      },
      "source": [
        "def get_cifar10(n_train=None):\n",
        "  train_X, train_y, test_X, test_y = cifar10_web.cifar10(path=None)\n",
        "\n",
        "  # NORMALIZE GLOBALLY\n",
        "  train_mean = train_X.mean()\n",
        "  train_std = train_X.std()\n",
        "  train_X = (train_X - train_mean)/train_std\n",
        "  test_X = (test_X - train_mean)/train_std\n",
        "  # NORMALIZE LOCALLY\n",
        "  train_X = train_X/((train_X**2).mean(axis=1)**.5)[:,None]\n",
        "  test_X = test_X/((test_X**2).mean(axis=1)**.5)[:,None]\n",
        "\n",
        "  if n_train is not None:\n",
        "    train_X = train_X[:n_train]\n",
        "    train_y = train_y[:n_train]\n",
        "\n",
        "  return train_X, train_y, test_X, test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE2r_BUi09Fo"
      },
      "source": [
        "Run some random input through a neural network to generate output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOC5nV0CTSrk"
      },
      "source": [
        "def get_teacher_dataset(d_in=10, d_out=1, width=1000, n_train=100, n_test=1000, n_hidden_layers=3, nonlinearity='relu', W_std=None, b_std=None):\n",
        "  # DRAW RANDOM POINTS\n",
        "  global key\n",
        "  key, split_key_1, split_key_2 = random.split(key, 3)\n",
        "  train_X = random.normal(split_key_1, (n_train, d_in))\n",
        "  test_X = random.normal(split_key_2, (n_test, d_in))\n",
        "\n",
        "  # NORMALIZE TO A HYPERSPHERE\n",
        "  train_X = train_X/((train_X**2).mean(axis=1)**.5)[:,None]\n",
        "  test_X = test_X/((test_X**2).mean(axis=1)**.5)[:,None]\n",
        "\n",
        "  # DEFINE TEACHER NET ARCHITECTURE\n",
        "  layers = None\n",
        "  if nonlinearity == 'relu':\n",
        "    W_std = W_std if W_std is not None else 1.5\n",
        "    b_std = b_std if b_std is not None else 0.05\n",
        "    layers = [stax.Dense(width, W_std=W_std, b_std=b_std), stax.Relu()]*n_hidden_layers\n",
        "  elif nonlinearity == 'erf':\n",
        "    W_std = W_std if W_std is not None else 2\n",
        "    b_std = b_std if b_std is not None else 0\n",
        "    layers = [stax.Dense(width, W_std=W_std, b_std=b_std), stax.Erf()]*n_hidden_layers\n",
        "  else:\n",
        "    assert False\n",
        "  layers += [stax.Dense(d_out, W_std=1, b_std=0)]\n",
        "  init_fn, apply_fn, _ = stax.serial(*layers)\n",
        "\n",
        "  key, net_key = random.split(key)\n",
        "  _, initial_params = init_fn(net_key, (-1, d_in))\n",
        "  apply_fn = jit(apply_fn)\n",
        "\n",
        "  # SAMPLE TARGETS\n",
        "  train_y = apply_fn(initial_params, train_X)\n",
        "  test_y = apply_fn(initial_params, test_X)\n",
        "\n",
        "  return train_X, train_y, test_X, test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwBBigUjVm6I"
      },
      "source": [
        "# Net setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUORWcTZVpBy"
      },
      "source": [
        "def get_net_functions(d_in, width, d_out, n_hidden_layers=1, phi=None, deg=40, centered=False, W_std=None, b_std=None):\n",
        "    global key\n",
        "\n",
        "    init_fn, apply_fn_uncentered, kernel_fn = None, None, None\n",
        "\n",
        "    # if there's a phi, make a net with activation function phi\n",
        "    if phi is not None and phi != 'relu':\n",
        "      if phi == 'erf':\n",
        "        W_std = W_std if W_std is not None else 1.5\n",
        "        b_std = b_std if b_std is not None else 0.3\n",
        "        layers = [stax.Dense(width, W_std=W_std, b_std=b_std), stax.Erf()]*n_hidden_layers\n",
        "        layers += [stax.Dense(d_out, W_std=1, b_std=0)]\n",
        "        init_fn, apply_fn_uncentered, kernel_fn = stax.serial(*layers)\n",
        "      else:\n",
        "        W_std = W_std if W_std is not None else 1   # in the case of pointwise nonlinearities, we use the variances from the proofs.\n",
        "        b_std = b_std if b_std is not None else 0\n",
        "        layers = [stax.Dense(width, W_std=W_std, b_std=b_std), stax.ElementwiseNumerical(fn=phi, deg=deg)]*n_hidden_layers\n",
        "        layers += [stax.Dense(d_out, W_std=1, b_std=0)]\n",
        "        init_fn, apply_fn_uncentered, kernel_fn = stax.serial(*layers)\n",
        "\n",
        "    # otherwise, make a relu net\n",
        "    else:\n",
        "      W_std = W_std if W_std is not None else 1.5\n",
        "      b_std = b_std if b_std is not None else 0.1\n",
        "      layers = [stax.Dense(width, W_std=W_std, b_std=b_std), stax.Relu()]*n_hidden_layers\n",
        "      layers += [stax.Dense(d_out, W_std=1, b_std=0)]\n",
        "      init_fn, apply_fn_uncentered, kernel_fn = stax.serial(*layers)\n",
        "\n",
        "    key, net_key = random.split(key)\n",
        "    _, initial_params = init_fn(net_key, (-1, d_in))\n",
        "    apply_fn = jit(apply_fn_uncentered) if not centered else jit(lambda params, x: apply_fn_uncentered(params, x) - apply_fn_uncentered(initial_params, x))\n",
        "\n",
        "    return init_fn, apply_fn, kernel_fn, initial_params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub-TU6xXBQ3o"
      },
      "source": [
        "def get_batched_kernel_fn(kernel_fn, k_batch_size=100):\n",
        "  def batched_kernel_fn(x1, x2, get=None):\n",
        "    x2 = x1 if x2 is None else x2\n",
        "    get = get[0] if get in [('nngp',),('ntk',)] else get\n",
        "    kernel_fn_jit = jit(lambda x1,x2: kernel_fn(x1, x2, get))\n",
        "    # subkernels = [kernel_fn(x1, x2[k_batch_size*i:min(k_batch_size*(i+1), x2.shape[0])], get=get) for i in range(int(np.ceil(x2.shape[0]/k_batch_size)))]\n",
        "    subkernels = [kernel_fn_jit(x1, x2[k_batch_size*i:min(k_batch_size*(i+1), x2.shape[0])]) for i in range(int(np.ceil(x2.shape[0]/k_batch_size)))]\n",
        "    output = np.concatenate(subkernels, axis=1)\n",
        "    return output\n",
        "  return batched_kernel_fn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoXf5h1uBRwr"
      },
      "source": [
        "mse = lambda y_hat, y_true: 0.5 * ((y_hat - y_true) ** 2).sum(axis=1).mean()\n",
        "percent_correct = jit(lambda y_hat, y_true: 100*(np.argmax(y_hat, axis=1) == np.argmax(y_true, axis=1)).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhOdUsgQu1XN"
      },
      "source": [
        "# Phi generation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akzIpEXhvwSn"
      },
      "source": [
        "def psd_poly_fit(xs, fs, deg=5):\n",
        "  Q = base_np.zeros((deg+1, deg+1))\n",
        "  p = base_np.zeros((deg+1,))\n",
        "  G = -1*base_np.eye(deg+1)\n",
        "  h = 0*p\n",
        "\n",
        "  for i in range(deg + 1):\n",
        "    for j in range(deg + 1):\n",
        "      Q[i][j] = 2*(xs**(i+j)).sum()\n",
        "  for i in range(deg + 1):\n",
        "    p[i] = -2*((xs**i)*fs).sum()\n",
        "  \n",
        "  Q = (10**3)*cvxopt.matrix(Q)\n",
        "  p = (10**3)*cvxopt.matrix(p)\n",
        "  G = cvxopt.matrix(G)\n",
        "  h = cvxopt.matrix(h)\n",
        "  \n",
        "  cvxopt.solvers.options['show_progress'] = False\n",
        "  sol = cvxopt.solvers.qp(Q, p, G, h)\n",
        "\n",
        "  return base_np.array(sol['x']).flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOSIQeNGvx5I"
      },
      "source": [
        "def poly_coeffs_to_lambda_fn_string(c_alpha):\n",
        "  output = \"lambda z: \"\n",
        "  for i in range(len(c_alpha)):\n",
        "    coeff = c_alpha[i]/factorial(i)\n",
        "    if coeff != 0:\n",
        "      output += str(coeff) + \"*z**\" + str(i) + \" + \"\n",
        "  return(output[:-3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQTvnII_u45i"
      },
      "source": [
        "def phi_from_kernel_fn(kernel_fn, k_type, deg=10, n_sample_pts=1000, weight_on_endpts=0):\n",
        "  d_in = 2\n",
        "  n_sample_pts = n_sample_pts\n",
        "  xis = np.linspace(1,-1,n_sample_pts)\n",
        "\n",
        "  # if weighting the endpoints higher, add more -1s and +1s to xis\n",
        "  if weight_on_endpts > 0:\n",
        "    n_interior_pts = int(n_sample_pts*(1 - 2*weight_on_endpts))\n",
        "    n_endpts = int(n_sample_pts*weight_on_endpts)\n",
        "    xis = np.linspace(1, -1, n_interior_pts + 2)\n",
        "    xis = np.concatenate([np.array([1]*(n_endpts - 1)), xis, np.array([-1]*(n_endpts - 1))])\n",
        "\n",
        "  sines = (1 - xis**2)**.5\n",
        "  u0 = index_update(np.zeros(d_in), 0, 1)\n",
        "  u1 = index_update(np.zeros(d_in), 1, 1)\n",
        "  xs = np.outer(xis, u0) + np.outer(sines, u1)\n",
        "  xs = (d_in**.5)*xs\n",
        "\n",
        "  Ks = kernel_fn(xs[0:1], xs, k_type)[0]\n",
        "\n",
        "  desired_coeffs = psd_poly_fit(xis, Ks, deg=deg)\n",
        "  desired_coeffs *= (np.array(np.abs(desired_coeffs) > 10**-3))\n",
        "  print('approximating K as a polynomial with coeffs', desired_coeffs)\n",
        "\n",
        "  # construct matrix for going from K (i.e. a_gamma) to phi (i.e. c_alpha)\n",
        "  Minv = [[(-1)**((col - row)/2)/factorial2(col - row)\n",
        "          if (col >= row)*((col + row)%2 == 0)\n",
        "          else 0\n",
        "          for col in range(deg + 1)]\n",
        "          for row in range(deg + 1)]\n",
        "  Minv = np.array(Minv)\n",
        "\n",
        "  a_gamma = [desired_coeffs[gamma]*factorial(gamma) if gamma < len(desired_coeffs) else 0 for gamma in range(len(Minv))]\n",
        "  b_gamma = np.array(a_gamma)**.5\n",
        "  c_alpha = np.matmul(Minv, np.array(b_gamma))\n",
        "\n",
        "  phi_def_string = poly_coeffs_to_lambda_fn_string(c_alpha)\n",
        "  phi = eval(phi_def_string)\n",
        "\n",
        "  string_to_print = '\\\\phi(z) = '\n",
        "  for alpha in range(len(c_alpha)):\n",
        "    coeff = c_alpha[alpha]/factorial(alpha)\n",
        "    if abs(coeff) > 10**-9:\n",
        "      if string_to_print[-2] != '=':\n",
        "        if coeff < 0:\n",
        "          string_to_print += ' - '\n",
        "        else:\n",
        "          string_to_print += ' + '\n",
        "      else:\n",
        "        if coeff < 0:\n",
        "          string_to_print += '-'\n",
        "      coeff = abs(coeff)\n",
        "      string_to_print += '{:6.4f}'.format(coeff)\n",
        "      if alpha > 0:\n",
        "        string_to_print += ' z'\n",
        "        if alpha > 1:\n",
        "          string_to_print += f'^{alpha}'\n",
        "  print('\\n' + string_to_print + '\\n')\n",
        "\n",
        "  return phi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_icmTGErjzQR"
      },
      "source": [
        "# Figure-makin' functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vofLRigLIpRc"
      },
      "source": [
        "def kernel_match_plot(ax, target_kernel, k_type='nngp', target_name='target', n_draws=100, x_axis_on=True, y_axis_label=\"$K(\\\\xi)$\", phi_deg=20, n_sample_pts=100, width=1000, d_out=1, plot_i=0, weight_on_endpts=0):\n",
        "  phi = phi_from_kernel_fn(target_kernel, k_type, deg=phi_deg, n_sample_pts=n_sample_pts, weight_on_endpts=weight_on_endpts)\n",
        "  init_fn_1phi, apply_fn_1phi, kernel_fn_1phi, _ = get_net_functions(d_in, width, d_out, n_hidden_layers=1, phi=phi)\n",
        "  # init_fn_1phi, apply_fn_1phi, kernel_fn_1phi, _ = get_net_functions(d_in, width, d_out, n_hidden_layers=5, phi='relu')\n",
        "  # init_fn_1phi, apply_fn_1phi, kernel_fn_1phi, _ = get_net_functions(d_in, width, d_out, n_hidden_layers=5, phi='erf', W_std=1.5, b_std=.3)\n",
        "\n",
        "  # INFINITE-WIDTH KERNELS\n",
        "  kernel_samples = {}\n",
        "  kernel_samples['target'] = target_kernel(xs[0:1], xs, k_type)[0][::-1]\n",
        "  kernel_samples['1 phi (nngp)'] = kernel_fn_1phi(xs[0:1], xs, 'nngp')[0][::-1]\n",
        "\n",
        "  # FINITE-WIDTH KERNEL\n",
        "  sample_sets = []\n",
        "  global key\n",
        "  for i in tqdm(range(n_draws)):\n",
        "    key, net_key = random.split(key)\n",
        "    _, initial_params = init_fn_1phi(net_key, (-1, d_in))\n",
        "    samples = apply_fn_1phi(initial_params, xs_sparse)\n",
        "    draw_correlations = (samples*samples[0]).sum(axis=1)/d_out\n",
        "    sample_sets += [draw_correlations.flatten()]\n",
        "  sample_sets = np.array(sample_sets)\n",
        "  finite_width_kernel = sample_sets.mean(axis=0)\n",
        "  finite_width_kernel_stds = sample_sets.std(axis=0)/n_draws**.5\n",
        "\n",
        "  c = 'ABCDEFGHI'[plot_i]\n",
        "  ax.plot(cosines, kernel_samples['target'], label=target_name, color=(.6,.8,1), lw=7)\n",
        "  ax.plot(cosines, kernel_samples['1 phi (nngp)'], label='1L $\\phi_'+c+'$ (NNGP)', color=(1,0,0), lw=2)\n",
        "  ax.scatter(cosines_sparse, finite_width_kernel, color=(.7,.0,0), label='1L $\\phi_'+c+'$ (empirical)', zorder=6)\n",
        "  ax.errorbar(cosines_sparse, finite_width_kernel, yerr=finite_width_kernel_stds, linestyle=\"None\", color=(1,0,0), zorder=5)\n",
        "\n",
        "  ax.tick_params(axis='both', labelsize=15)\n",
        "  ax.set_xlabel(\"$\\\\xi$\", fontsize=20)\n",
        "  if not x_axis_on:\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_xticklabels([])\n",
        "  ax.set_ylabel(y_axis_label, fontsize=20)\n",
        "  ax.legend(frameon=False, fontsize=14,\n",
        "            loc=(.03,.52) if plot_i < 6 else (.03, .53) if plot_i==6 else None)\n",
        "  \n",
        "  ax.set_xlim((-1.02,1.02))\n",
        "\n",
        "  return phi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24qFZ0v0B6tk"
      },
      "source": [
        "def phi_set_plot(ax, phis):\n",
        "  zs = np.linspace(-2.5, 2.5, 500)\n",
        "  letters = 'ABCDEFGH'\n",
        "  linestyles = [(1,0), (5,1), (3,1), (2,2), (2,1.3), (2,.8), (1,1), (1,1,3,1)]\n",
        "  colors = [(1,0,0), (1,.5,0), (.8,.7,0), (0,.7,0), (0,.5,.7), (0,0,1), (.5,0,.8), (1,0,1)]\n",
        "\n",
        "  for i, phi in enumerate(phis):\n",
        "    c = letters[i]\n",
        "    ax.plot(zs, phi(zs), label='$\\\\phi_'+c+'$', lw=3, linestyle=(0,linestyles[i]), color=colors[i])\n",
        "  ax.set_xlim((min(zs), max(zs)))\n",
        "\n",
        "  ax.set_xlabel('z', fontsize=20)\n",
        "  ax.set_ylabel('$\\\\phi(z)$', fontsize=20, labelpad=-10)\n",
        "  ax.tick_params(axis='both', labelsize=15)\n",
        "\n",
        "  ax.legend(frameon=False, fontsize=12, ncol=2, labelspacing=0, columnspacing=1, loc=(.4, .02))#(.17,.63))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnhygAyMHNfT"
      },
      "source": [
        "# Set up sample points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH6M7ob0HPdV"
      },
      "source": [
        "d_in = 2\n",
        "\n",
        "n_sample_pts = 1000\n",
        "# cosines of angles between points, called \"xi\" in the paper\n",
        "cosines = np.linspace(-1,1,n_sample_pts)\n",
        "sines = (1 - cosines**2)**.5\n",
        "\n",
        "u0 = index_update(np.zeros(d_in), 0, 1)\n",
        "u1 = index_update(np.zeros(d_in), 1, 1)\n",
        "xs = np.outer(cosines, u0) + np.outer(sines, u1)\n",
        "xs = (d_in**.5)*xs\n",
        "\n",
        "n_sample_pts_sparse = 21\n",
        "cosines_sparse = np.linspace(1,-1,n_sample_pts_sparse)\n",
        "sines_sparse = (1 - cosines_sparse**2)**.5\n",
        "xs_sparse = np.outer(cosines_sparse, u0) + np.outer(sines_sparse, u1)\n",
        "xs_sparse = (d_in**.5)*xs_sparse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VU4CfFzGRRf"
      },
      "source": [
        "# Make figure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m46jEjkJGSZ6"
      },
      "source": [
        "kwargs = {\n",
        "    'n_draws':10000,\n",
        "    'phi_deg':7,\n",
        "    'n_sample_pts':1000,\n",
        "    'width':10000,\n",
        "    'd_out':100,\n",
        "    'weight_on_endpts':.1\n",
        "    }\n",
        "\n",
        "n_layers_relu = 4\n",
        "n_layers_erf = 4\n",
        "\n",
        "fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(15,10))\n",
        "axs = axs.flatten()\n",
        "\n",
        "phis = [None]*8\n",
        "\n",
        "i = 0\n",
        "_, _, target_kernel, _ = get_net_functions(d_in, 1000, 1, n_hidden_layers=n_layers_relu, phi='relu')\n",
        "phis[i] = kernel_match_plot(axs[i], target_kernel, target_name=str(n_layers_relu)+'L ReLU (NNGP)', **kwargs, plot_i=i)\n",
        "\n",
        "i = 1\n",
        "_, _, target_kernel, _ = get_net_functions(d_in, 1000, 1, n_hidden_layers=n_layers_relu, phi='relu')\n",
        "phis[i] = kernel_match_plot(axs[i], target_kernel, k_type='ntk', target_name=str(n_layers_relu)+'L ReLU (NTK)', y_axis_label='', **kwargs, plot_i=i)\n",
        "\n",
        "i = 2\n",
        "_, _, target_kernel, _ = get_net_functions(d_in, 1000, 1, n_hidden_layers=n_layers_erf, phi='erf')\n",
        "phis[i] = kernel_match_plot(axs[i], target_kernel, target_name=str(n_layers_erf)+'L Erf (NNGP)', y_axis_label='', **kwargs, plot_i=i)\n",
        "\n",
        "i = 3\n",
        "_, _, target_kernel, _ = get_net_functions(d_in, 1000, 1, n_hidden_layers=n_layers_erf, phi='erf')\n",
        "phis[i] = kernel_match_plot(axs[i], target_kernel, k_type='ntk', target_name=str(n_layers_erf)+'L Erf (NTK)', **kwargs, plot_i=i)\n",
        "\n",
        "i = 4\n",
        "poly_fn = lambda xi: xi**4 + xi\n",
        "target_kernel = lambda x1, x2, get=None: poly_fn(np.matmul(x1, x2.transpose())/d_in)\n",
        "phis[i] = kernel_match_plot(axs[i], target_kernel, target_name='$K(\\\\xi) = \\\\xi^4 + \\\\xi$', y_axis_label='', **kwargs, plot_i=i)\n",
        "\n",
        "i = 5\n",
        "poly_fn = lambda xi: xi**5 + 3\n",
        "target_kernel = lambda x1, x2, get=None: poly_fn(np.matmul(x1, x2.transpose())/d_in)\n",
        "phis[i] = kernel_match_plot(axs[i], target_kernel, target_name='$K(\\\\xi) = \\\\xi^5 + 3$', y_axis_label='', **kwargs, plot_i=i)\n",
        "\n",
        "i = 6\n",
        "poly_fn = lambda xi: np.sinh(2*xi)\n",
        "target_kernel = lambda x1, x2, get=None: poly_fn(np.matmul(x1, x2.transpose())/d_in)\n",
        "phis[i] = kernel_match_plot(axs[i], target_kernel, target_name='$K(\\\\xi) = \\sinh(2 \\\\xi)$', **kwargs, plot_i=i)\n",
        "\n",
        "i = 7\n",
        "poly_fn = lambda xi: np.cosh(2*xi)\n",
        "target_kernel = lambda x1, x2, get=None: poly_fn(np.matmul(x1, x2.transpose())/d_in)\n",
        "phis[i] = kernel_match_plot(axs[i], target_kernel, target_name='$K(\\\\xi) = \\cosh(2 \\\\xi)$', y_axis_label='', **kwargs, plot_i=i)\n",
        "\n",
        "phi_set_plot(axs[8], phis)\n",
        "\n",
        "for i in range(len(axs)):\n",
        "  axs[i].text(.95, .05, 'ABCDEFGHI'[i], transform=axs[i].transAxes, size=20, weight='bold', ha='center')\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.savefig('fig1.png', transparent=True, dpi=300, bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aprXzWyHQGmK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}